{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53600,
     "status": "ok",
     "timestamp": 1637156505200,
     "user": {
      "displayName": "Marco Muscas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjMPN4p7OdEpxHE-vMDXuAgIYFhTiNp3yDm66R_hw=s64",
      "userId": "02166065583955404711"
     },
     "user_tz": 0
    },
    "id": "D9uUFaI_K38Y",
    "outputId": "5d82b9c8-c125-456a-fb14-9e306db3a833"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 0,
     "status": "ok",
     "timestamp": 1637156505200,
     "user": {
      "displayName": "Marco Muscas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjMPN4p7OdEpxHE-vMDXuAgIYFhTiNp3yDm66R_hw=s64",
      "userId": "02166065583955404711"
     },
     "user_tz": 0
    },
    "id": "gXFtXhC8LCZI",
    "outputId": "acf7fe69-b5f0-4ea5-acec-10e7047c0a17"
   },
   "outputs": [],
   "source": [
    "cd \"/content/drive/MyDrive/AML_Assignment_2_2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1637156505900,
     "user": {
      "displayName": "Marco Muscas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjMPN4p7OdEpxHE-vMDXuAgIYFhTiNp3yDm66R_hw=s64",
      "userId": "02166065583955404711"
     },
     "user_tz": 0
    },
    "id": "JsxsDrRiLEJo",
    "outputId": "6f205c06-2dd4-4cfa-9f54-1f8f5e953676"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26900,
     "status": "ok",
     "timestamp": 1637156532800,
     "user": {
      "displayName": "Marco Muscas",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GjMPN4p7OdEpxHE-vMDXuAgIYFhTiNp3yDm66R_hw=s64",
      "userId": "02166065583955404711"
     },
     "user_tz": 0
    },
    "id": "NOB_Onu6mxBY",
    "outputId": "c43f8dc1-87a1-4b7c-ab10-d51d2150b78d"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Thu Nov 11 17:09:22 2021\n",
    "\n",
    "@author: marco\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ex3_convnet_utils import get_dataset_loaders, weights_init, PrintModelSize, VisualizeFilter\n",
    "from ex3_convnet_utils import ConvNet\n",
    "from ex3_convnet_utils import complete_training_and_validation\n",
    "from ex3_convnet_utils import test_model\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "gridsearch_data_default_path = \"ex3_convnet_gridsearch_results_complete.csv\"\n",
    "train_valid_plot_root = \"./train_valid_history_plots/\"\n",
    "valid_accuracy_history_root = \"./valid_accuracy_history_plots/\"\n",
    "pre_training_filters_root = \"./pre_training_filters/\"\n",
    "post_training_filters_root = \"./post_training_filters/\"\n",
    "\n",
    "gridsearch_data = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    gridsearch_data = pd.read_csv(gridsearch_data_default_path, sep = ';', index_col = None)\n",
    "    print(\"Number of lines in csv: \", len(gridsearch_data))\n",
    "    \n",
    "except Exception as E:\n",
    "    print(E)\n",
    "    print(\"No worries! Seems like this is the first run, or maybe the file is actually not there.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-kXNyzztgP3A",
    "outputId": "f01d4997-8ae1-433a-e505-1fef0eefffed"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "index_last_checkpoint = len(gridsearch_data.index) # Will use this to get to the last permutation of hyperparameters\n",
    "    \n",
    "    \n",
    "cols = ['num_epochs', 'batch_size', 'hidden_size', 'learning_rate', 'lr_decay', 'reg', 'norm_layer', \n",
    "        'history_loss_train', 'history_loss_validation', 'best_model_valid_accuracy', 'early_stopped_valid_accuracy', 'is_early_stopped', 'train_valid_loss_hist_plot_path',\n",
    "        'valid_accuracy_plot_path', 'path_pre_train_filter_plots', 'path_post_train_filter_plots', 'best_model_test_accuracy', 'early_stopped_best_accuracy']\n",
    "\n",
    "\n",
    "\n",
    "''' DATA LOADING '''\n",
    "\n",
    "data_aug_transforms = []\n",
    "#data_aug_transforms.append(transforms.ColorJitter(brightness=.5, hue=.05, saturation=.05))\n",
    "#data_aug_transforms.append(transforms.RandomPerspective(distortion_scale=0.6, p=1.0))\n",
    "#data_aug_transforms.append(transforms.RandomHorizontalFlip(p=0.3))\n",
    "#data_aug_transforms.append(transforms.RandomRotation(20))\n",
    "#data_aug_transforms.append(transforms.RandomInvert(p=0.2))\n",
    "\n",
    "''' END OF DATA LOADING '''\n",
    "\n",
    "input_size = 3\n",
    "num_classes = 10\n",
    "hidden_size = [128, 512, 512, 512, 512]\n",
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "norm_layer = 'BN'\n",
    "\n",
    "\n",
    "num_epochs_gs = [5, 10, 30, 50]\n",
    "batch_size_gs = [200, 400]\n",
    "learning_rate_gs = [1e-3, 2e-3, 1e-2]\n",
    "learning_rate_decay_gs = [0.99, 0.95, 0.9]\n",
    "reg_gs = [0.001, 0.005]\n",
    "\n",
    "print(\"Starting training now...\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device: %s'%device)\n",
    "\n",
    "current_iteration = 0\n",
    "\n",
    "for num_epochs in num_epochs_gs:\n",
    "    for batch_size in batch_size_gs:\n",
    "        for learning_rate in learning_rate_gs:\n",
    "            for learning_rate_decay in learning_rate_decay_gs:\n",
    "                for reg in reg_gs:\n",
    "                    \n",
    "\n",
    "                    if current_iteration >= index_last_checkpoint: # Using the rows of the dataframe, I can go back to the last combination of parameters\n",
    "                        \n",
    "                        train_loader, val_loader, test_loader = get_dataset_loaders(data_aug_transforms,\n",
    "                                                                batch_size,\n",
    "                                                                num_training, \n",
    "                                                                num_validation)\n",
    "\n",
    "                        \n",
    "                        model = ConvNet(input_size, hidden_size, num_classes, norm_layer=norm_layer).to(device)\n",
    "                        model.apply(weights_init)\n",
    "                        \n",
    "                        # Model size and filters before training (model size does not change)\n",
    "                        PrintModelSize(model)\n",
    "                        \n",
    "                        full_path_pre_train_filter_plots = str(pre_training_filters_root + str(\"pre_training_filters_{}_{}_{}_{}_{}.png\".format(num_epochs, batch_size, learning_rate,\n",
    "                                                                                                                  learning_rate_decay, reg)))\n",
    "                        \n",
    "                        VisualizeFilter(model, full_path_pre_train_filter_plots, save_to_disk = True, prefix = \"Pre-training | \")\n",
    "                        \n",
    "                        \n",
    "                        criterion = nn.CrossEntropyLoss()\n",
    "                        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=reg)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        results = complete_training_and_validation(model = model,\n",
    "                                                        num_epochs = num_epochs,\n",
    "                                                        train_loader = train_loader,\n",
    "                                                        val_loader = val_loader,\n",
    "                                                        device = device,\n",
    "                                                        learning_rate = learning_rate,\n",
    "                                                        learning_rate_decay = learning_rate_decay,\n",
    "                                                        reg = reg,\n",
    "                                                        batch_size = batch_size)\n",
    "                        \n",
    "                        \n",
    "                        best_model = results[0]\n",
    "                        early_stopped_model = results[1]\n",
    "                        loss_train = results[2]\n",
    "                        loss_val = results[3]\n",
    "                        best_model_accuracy = results[4]\n",
    "                        early_stopped_accuracy = results[5]\n",
    "                        is_early_stopped = results[6]\n",
    "                        accuracy_val = results[7]\n",
    "                        \n",
    "                        best_model_test_accuracy = np.nan\n",
    "                        early_stopped_test_accuracy = np.nan\n",
    "                        \n",
    "                        print(\"Early stopped flag: \", is_early_stopped)\n",
    "                        \n",
    "                        if best_model != None:\n",
    "                            best_model_test_accuracy = test_model(best_model, test_loader, device)\n",
    "                            print(\"Best model test accuracy: \", best_model_test_accuracy)\n",
    "                            \n",
    "                        if early_stopped_model != None:\n",
    "                            early_stopped_test_accuracy = test_model(early_stopped_model, test_loader, device)\n",
    "                            print(\"Early stopped test accuracy: \", early_stopped_test_accuracy)\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        full_path_post_train_filter_plots = str(post_training_filters_root + str(\"post_training_filters_{}_{}_{}_{}_{}.png\".format(num_epochs, batch_size, learning_rate,\n",
    "                                                                                                                  learning_rate_decay, reg)))\n",
    "                        \n",
    "                        VisualizeFilter(model, full_path_post_train_filter_plots, save_to_disk = True, prefix = \"Post-training | \")\n",
    "                        \n",
    "\n",
    "                        \n",
    "                        \n",
    "                        plt.figure(2, figsize = (7,5))\n",
    "                        \n",
    "                        train_val_loss_hist_title = \"Training-Validation loss history > \" \n",
    "                        train_val_loss_hist_title += str(\"Epochs: {} | Batch size: {} \\n Learning Rate: {} | LR Decay: {} | Reg: {}\".format(num_epochs, batch_size, \n",
    "                                                                                                                                          learning_rate,\n",
    "                                                                                                                                          learning_rate_decay,\n",
    "                                                                                                                                          reg))\n",
    "                        \n",
    "                        plt.suptitle(train_val_loss_hist_title)\n",
    "                        \n",
    "                        \n",
    "                        plt.plot(loss_train, 'r', label='Train loss')\n",
    "                        plt.plot(loss_val, 'g', label='Val loss')\n",
    "                        plt.xlabel(\"Epoch\")\n",
    "                        plt.ylabel(\"Loss\")\n",
    "                        plt.legend()\n",
    "                        full_path_train_valid_loss_plots = str(train_valid_plot_root + str(\"train_val_loss_hist_{}_{}_{}_{}_{}.png\".format(num_epochs, batch_size, learning_rate,\n",
    "                                                                                                                  learning_rate_decay, reg)))\n",
    "                        plt.savefig(full_path_train_valid_loss_plots)\n",
    "                        \n",
    "                        plt.close()\n",
    "                        \n",
    "                        plt.figure(3, figsize = (7,5))\n",
    "                        \n",
    "                        train_val_accuracy_title = \"Accuracy history > \"\n",
    "                        train_val_accuracy_title += str(\"Epochs: {} | Batch size: {} \\n Learning Rate: {} | LR Decay: {} | Reg: {}\".format(num_epochs, batch_size, \n",
    "                                                                                                                                          learning_rate,\n",
    "                                                                                                                                          learning_rate_decay,\n",
    "                                                                                                                                          reg))\n",
    "                        \n",
    "                        plt.suptitle(train_val_accuracy_title)\n",
    "                        plt.xlabel(\"Epoch\")\n",
    "                        plt.ylabel(\"Accuracy\")\n",
    "                        \n",
    "                        plt.plot(accuracy_val, 'r', label='Validation accuracy')\n",
    "                        plt.legend()\n",
    "                        \n",
    "                        full_path_valid_accuracy_plots = str(valid_accuracy_history_root + str(\"valid_accuracy_hist_{}_{}_{}_{}_{}.png\".format(num_epochs, batch_size, learning_rate,\n",
    "                                                                                                                                        learning_rate_decay, reg)))\n",
    "                        plt.savefig(full_path_valid_accuracy_plots)\n",
    "\n",
    "                        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                        \n",
    "                        new_row = pd.DataFrame(data = [[num_epochs, batch_size, hidden_size, learning_rate, learning_rate_decay, reg, norm_layer,\n",
    "                                                        loss_train, loss_val, best_model_accuracy, early_stopped_accuracy, is_early_stopped,\n",
    "                                                        full_path_train_valid_loss_plots, full_path_valid_accuracy_plots, \n",
    "                                                        full_path_pre_train_filter_plots, full_path_post_train_filter_plots,\n",
    "                                                        best_model_test_accuracy, early_stopped_test_accuracy]], columns = cols)\n",
    "                        \n",
    "                        gridsearch_data = gridsearch_data.append(new_row, ignore_index = True)\n",
    "                        \n",
    "                        gridsearch_data.to_csv(gridsearch_data_default_path, sep = ';', na_rep = 'nan', index = False)                     \n",
    "                        print(\"\\n\")\n",
    "                    else:\n",
    "                        print(\"Skipping iteration, currently at: \", current_iteration)\n",
    "                        \n",
    "                    current_iteration += 1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPe+/DsPwYOMsGa2MIm1SCm",
   "collapsed_sections": [],
   "name": "AML_Assignment_2_GridSearch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
