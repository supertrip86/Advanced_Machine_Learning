{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ff6ba9",
   "metadata": {
    "id": "51ff6ba9"
   },
   "outputs": [],
   "source": [
    "# Importing all Libraries\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import itertools\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
    "from keras.models import Sequential \n",
    "from tensorflow.keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense \n",
    "from tensorflow.keras import applications \n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import math \n",
    "import datetime\n",
    "import time\n",
    "import tqdm.notebook as tq\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d925a37",
   "metadata": {
    "id": "6d925a37"
   },
   "source": [
    "### Bottle Neck Features\n",
    "* <b>Model used:</b>  VGG16\n",
    "* All <b>Bottleneck Features</b> from sequential model of VGG16 each feature dataset is saved as .npy file, to be classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a42517c",
   "metadata": {
    "id": "9a42517c"
   },
   "outputs": [],
   "source": [
    "# Setting input dataset size and batch size\n",
    "img_width, img_height = 64, 64 \n",
    "batch_size = 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe3617d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "dc614f2308e34444b6874503507dd858",
      "245fbd7f51904e7b8693c3b4fa92f13b",
      "8e31b6e5bfc3432588afe98fd7c51421",
      "0753047ff6bc463bbbaaadd1e8843b66",
      "9288f87ef8a748cdb256907c80e96481",
      "963e4cde82ee4a009f0c33926612cf97",
      "df8d7760414a4491ae02a72058a56bb7",
      "a6fbc9664cf243bdbaf663956add756e",
      "b5fb59a281014af48e96e1742bffaa08",
      "5e2e4fce17b14b1092b1fb8efe029935",
      "37f7c3d87c154a9fb19942a08df9c4fe"
     ]
    },
    "id": "fe3617d9",
    "outputId": "f5c3a010-c50a-408b-c6c5-9b95ba97a9ae",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ace2fdff8be43b195d1619af1986bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 17s 82ms/step - loss: 2.0284 - accuracy: 0.2100 - val_loss: 1.8899 - val_accuracy: 0.2551\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.8755 - accuracy: 0.2375 - val_loss: 1.8437 - val_accuracy: 0.2092\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.8244 - accuracy: 0.2425 - val_loss: 1.8334 - val_accuracy: 0.2551\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.7964 - accuracy: 0.2575 - val_loss: 1.8325 - val_accuracy: 0.2551\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 2.4560 - accuracy: 0.2325 - val_loss: 1.8400 - val_accuracy: 0.2704\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.8814 - accuracy: 0.2925 - val_loss: 1.8605 - val_accuracy: 0.2551\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.9111 - accuracy: 0.1925 - val_loss: 1.8968 - val_accuracy: 0.3724\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.7980 - accuracy: 0.2850 - val_loss: 1.6583 - val_accuracy: 0.2092\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.8158 - accuracy: 0.3825 - val_loss: 1.4019 - val_accuracy: 0.5357\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.4044 - accuracy: 0.5050 - val_loss: 1.0891 - val_accuracy: 0.6020\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.3139 - accuracy: 0.5400 - val_loss: 1.1087 - val_accuracy: 0.5969\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.4185 - accuracy: 0.5300 - val_loss: 3.3770 - val_accuracy: 0.4949\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.3554 - accuracy: 0.5450 - val_loss: 0.9416 - val_accuracy: 0.6173\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.0598 - accuracy: 0.5800 - val_loss: 0.8356 - val_accuracy: 0.6582\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.9530 - accuracy: 0.5950 - val_loss: 0.9099 - val_accuracy: 0.6173\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.9725 - accuracy: 0.6275 - val_loss: 0.8576 - val_accuracy: 0.7296\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.9399 - accuracy: 0.6350 - val_loss: 0.8959 - val_accuracy: 0.6735\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.8713 - accuracy: 0.6700 - val_loss: 0.8153 - val_accuracy: 0.6684\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.9626 - accuracy: 0.6475 - val_loss: 0.8724 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.7974 - accuracy: 0.6900 - val_loss: 0.7364 - val_accuracy: 0.6837\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.8537 - accuracy: 0.7050 - val_loss: 0.7470 - val_accuracy: 0.6327\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.7156 - accuracy: 0.7175 - val_loss: 0.7439 - val_accuracy: 0.7398\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.7098 - accuracy: 0.7425 - val_loss: 0.5485 - val_accuracy: 0.7551\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.7389 - accuracy: 0.7100 - val_loss: 0.5855 - val_accuracy: 0.7755\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.6657 - accuracy: 0.7075 - val_loss: 0.4484 - val_accuracy: 0.8163\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.7025 - accuracy: 0.7325 - val_loss: 0.8389 - val_accuracy: 0.8010\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.5399 - accuracy: 0.5225 - val_loss: 1.0029 - val_accuracy: 0.6327\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.9772 - accuracy: 0.6875 - val_loss: 0.7863 - val_accuracy: 0.7347\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.8063 - accuracy: 0.7350 - val_loss: 0.9679 - val_accuracy: 0.7296\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.6362 - accuracy: 0.7425 - val_loss: 0.4393 - val_accuracy: 0.8010\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.6413 - accuracy: 0.7325 - val_loss: 0.4021 - val_accuracy: 0.8418\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.5346 - accuracy: 0.8225 - val_loss: 0.4929 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4970 - accuracy: 0.8100 - val_loss: 0.3690 - val_accuracy: 0.8571\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.7070 - accuracy: 0.7625 - val_loss: 0.3821 - val_accuracy: 0.8571\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.6605 - accuracy: 0.7825 - val_loss: 0.4739 - val_accuracy: 0.7857\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.5898 - accuracy: 0.7950 - val_loss: 0.3517 - val_accuracy: 0.8673\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.4729 - accuracy: 0.8175 - val_loss: 0.3758 - val_accuracy: 0.8673\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4582 - accuracy: 0.8475 - val_loss: 0.2697 - val_accuracy: 0.9082\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.4268 - accuracy: 0.8475 - val_loss: 0.3978 - val_accuracy: 0.8673\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.5160 - accuracy: 0.7875 - val_loss: 0.3388 - val_accuracy: 0.8469\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.6743 - accuracy: 0.7725 - val_loss: 0.4810 - val_accuracy: 0.8418\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.5616 - accuracy: 0.8025 - val_loss: 0.4416 - val_accuracy: 0.8418\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.5490 - accuracy: 0.8075 - val_loss: 0.3148 - val_accuracy: 0.9286\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.4415 - accuracy: 0.8325 - val_loss: 0.5529 - val_accuracy: 0.8418\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4843 - accuracy: 0.8175 - val_loss: 0.4394 - val_accuracy: 0.8776\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.5229 - accuracy: 0.8400 - val_loss: 0.2921 - val_accuracy: 0.8776\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4919 - accuracy: 0.8225 - val_loss: 0.2358 - val_accuracy: 0.9235\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4180 - accuracy: 0.8550 - val_loss: 0.4820 - val_accuracy: 0.8316\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.5255 - accuracy: 0.8100 - val_loss: 0.3614 - val_accuracy: 0.8571\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4941 - accuracy: 0.8225 - val_loss: 0.3352 - val_accuracy: 0.8929\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.4926 - accuracy: 0.8250 - val_loss: 0.3612 - val_accuracy: 0.8520\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3910 - accuracy: 0.8550 - val_loss: 0.2509 - val_accuracy: 0.9082\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4702 - accuracy: 0.8400 - val_loss: 0.2575 - val_accuracy: 0.9082\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.3550 - accuracy: 0.8725 - val_loss: 0.6751 - val_accuracy: 0.7908\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5572 - accuracy: 0.8250 - val_loss: 0.4978 - val_accuracy: 0.8316\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4098 - accuracy: 0.8625 - val_loss: 0.2222 - val_accuracy: 0.9184\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5781 - accuracy: 0.8025 - val_loss: 0.8074 - val_accuracy: 0.8776\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.6337 - accuracy: 0.7725 - val_loss: 0.3944 - val_accuracy: 0.8265\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.4354 - accuracy: 0.8325 - val_loss: 0.2352 - val_accuracy: 0.9133\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.4008 - accuracy: 0.8575 - val_loss: 0.3513 - val_accuracy: 0.8673\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4548 - accuracy: 0.8275 - val_loss: 0.4152 - val_accuracy: 0.8418\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.4703 - accuracy: 0.8275 - val_loss: 0.2629 - val_accuracy: 0.9184\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4440 - accuracy: 0.8525 - val_loss: 0.2099 - val_accuracy: 0.9286\n",
      "fullImage Train Shape: (778, 2, 2, 512)\n",
      "fullImage Val Shape: (196, 2, 2, 512)\n",
      "Time training0:  0:17:01.365912\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 17s 82ms/step - loss: 3.7329 - accuracy: 0.1825 - val_loss: 2.4681 - val_accuracy: 0.1786\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 2.0222 - accuracy: 0.2275 - val_loss: 1.8623 - val_accuracy: 0.2551\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.9003 - accuracy: 0.2400 - val_loss: 1.8941 - val_accuracy: 0.2551\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.9511 - accuracy: 0.1975 - val_loss: 1.7811 - val_accuracy: 0.3980\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8387 - accuracy: 0.2825 - val_loss: 1.7752 - val_accuracy: 0.3214\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8435 - accuracy: 0.3050 - val_loss: 1.7807 - val_accuracy: 0.3112\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.7650 - accuracy: 0.3175 - val_loss: 1.7772 - val_accuracy: 0.3112\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.6283 - accuracy: 0.3925 - val_loss: 1.5890 - val_accuracy: 0.4490\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.6027 - accuracy: 0.4275 - val_loss: 1.4571 - val_accuracy: 0.5153\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.5873 - accuracy: 0.4100 - val_loss: 1.3243 - val_accuracy: 0.5153\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.5427 - accuracy: 0.4750 - val_loss: 1.3857 - val_accuracy: 0.5051\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.5165 - accuracy: 0.5350 - val_loss: 1.6036 - val_accuracy: 0.3418\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 15s 78ms/step - loss: 1.5412 - accuracy: 0.4500 - val_loss: 1.3118 - val_accuracy: 0.5510\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.3525 - accuracy: 0.5000 - val_loss: 1.3095 - val_accuracy: 0.5408\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4348 - accuracy: 0.5050 - val_loss: 1.3245 - val_accuracy: 0.5612\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.3179 - accuracy: 0.5300 - val_loss: 1.3046 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3818 - accuracy: 0.5025 - val_loss: 1.2611 - val_accuracy: 0.5255\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.2721 - accuracy: 0.5450 - val_loss: 1.2021 - val_accuracy: 0.5867\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.5019 - accuracy: 0.5000 - val_loss: 1.2989 - val_accuracy: 0.5051\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.3808 - accuracy: 0.5150 - val_loss: 1.1644 - val_accuracy: 0.5969\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.2792 - accuracy: 0.5800 - val_loss: 1.3181 - val_accuracy: 0.5357\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.2494 - accuracy: 0.5725 - val_loss: 1.2516 - val_accuracy: 0.5408\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.3823 - accuracy: 0.5125 - val_loss: 1.3305 - val_accuracy: 0.5255\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.3181 - accuracy: 0.5450 - val_loss: 1.0658 - val_accuracy: 0.6327\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.3173 - accuracy: 0.5125 - val_loss: 1.3898 - val_accuracy: 0.4337\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.2705 - accuracy: 0.5200 - val_loss: 0.9920 - val_accuracy: 0.6173\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.3411 - accuracy: 0.5200 - val_loss: 1.1570 - val_accuracy: 0.5663\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.3069 - accuracy: 0.5275 - val_loss: 1.0825 - val_accuracy: 0.5918\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.2239 - accuracy: 0.5650 - val_loss: 1.1166 - val_accuracy: 0.5969\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.2439 - accuracy: 0.5775 - val_loss: 1.0778 - val_accuracy: 0.6224\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.1381 - accuracy: 0.6125 - val_loss: 1.0172 - val_accuracy: 0.6122\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.2122 - accuracy: 0.5675 - val_loss: 1.2072 - val_accuracy: 0.5357\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1436 - accuracy: 0.6025 - val_loss: 1.0633 - val_accuracy: 0.6122\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.1758 - accuracy: 0.5725 - val_loss: 0.9815 - val_accuracy: 0.6531\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.1504 - accuracy: 0.6050 - val_loss: 0.9974 - val_accuracy: 0.6327\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 15s 78ms/step - loss: 1.1961 - accuracy: 0.5950 - val_loss: 1.3032 - val_accuracy: 0.4949\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1539 - accuracy: 0.6125 - val_loss: 1.4105 - val_accuracy: 0.6276\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.1550 - accuracy: 0.6000 - val_loss: 0.9926 - val_accuracy: 0.6378\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.2055 - accuracy: 0.5925 - val_loss: 1.0358 - val_accuracy: 0.6327\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.1776 - accuracy: 0.5950 - val_loss: 0.9780 - val_accuracy: 0.6531\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4955 - accuracy: 0.5250 - val_loss: 1.2278 - val_accuracy: 0.5561\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.2606 - accuracy: 0.5550 - val_loss: 1.2234 - val_accuracy: 0.5663\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1206 - accuracy: 0.6000 - val_loss: 1.0296 - val_accuracy: 0.6071\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.2044 - accuracy: 0.5700 - val_loss: 1.0138 - val_accuracy: 0.6429\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.0959 - accuracy: 0.6000 - val_loss: 1.1000 - val_accuracy: 0.6020\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0840 - accuracy: 0.6000 - val_loss: 1.0651 - val_accuracy: 0.6071\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0658 - accuracy: 0.6100 - val_loss: 0.9301 - val_accuracy: 0.6480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 1.1148 - accuracy: 0.5975 - val_loss: 1.5190 - val_accuracy: 0.5663\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1044 - accuracy: 0.6175 - val_loss: 1.0742 - val_accuracy: 0.6224\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1025 - accuracy: 0.6300 - val_loss: 0.9994 - val_accuracy: 0.6122\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.2334 - accuracy: 0.5750 - val_loss: 1.0158 - val_accuracy: 0.6429\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0904 - accuracy: 0.6300 - val_loss: 0.9702 - val_accuracy: 0.6531\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1454 - accuracy: 0.5925 - val_loss: 0.9303 - val_accuracy: 0.6582\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1715 - accuracy: 0.5850 - val_loss: 1.1546 - val_accuracy: 0.5714\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.1088 - accuracy: 0.5950 - val_loss: 1.0170 - val_accuracy: 0.6582\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0755 - accuracy: 0.6325 - val_loss: 0.9604 - val_accuracy: 0.6480\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1042 - accuracy: 0.5925 - val_loss: 1.1020 - val_accuracy: 0.6480\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0450 - accuracy: 0.6150 - val_loss: 0.9761 - val_accuracy: 0.6531\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1507 - accuracy: 0.6275 - val_loss: 0.9826 - val_accuracy: 0.6378\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1039 - accuracy: 0.5875 - val_loss: 0.9245 - val_accuracy: 0.6684\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1306 - accuracy: 0.6025 - val_loss: 0.9636 - val_accuracy: 0.6429\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0608 - accuracy: 0.6175 - val_loss: 1.0016 - val_accuracy: 0.6429\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0850 - accuracy: 0.6150 - val_loss: 1.4027 - val_accuracy: 0.6071\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.1891 - accuracy: 0.5900 - val_loss: 0.9950 - val_accuracy: 0.6327\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.9959 - accuracy: 0.6725 - val_loss: 0.9179 - val_accuracy: 0.6633\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0568 - accuracy: 0.6150 - val_loss: 0.9361 - val_accuracy: 0.6735\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0329 - accuracy: 0.6325 - val_loss: 1.0959 - val_accuracy: 0.6122\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.0333 - accuracy: 0.6350 - val_loss: 0.9141 - val_accuracy: 0.6990\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1222 - accuracy: 0.6125 - val_loss: 1.0265 - val_accuracy: 0.6224\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1366 - accuracy: 0.5825 - val_loss: 1.0013 - val_accuracy: 0.6582\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.0468 - accuracy: 0.6600 - val_loss: 0.9469 - val_accuracy: 0.6531\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.9904 - accuracy: 0.6625 - val_loss: 0.8763 - val_accuracy: 0.6888\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9219 - accuracy: 0.6600 - val_loss: 0.9090 - val_accuracy: 0.6378\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1210 - accuracy: 0.6250 - val_loss: 0.9799 - val_accuracy: 0.6429\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 1.1309 - accuracy: 0.5900 - val_loss: 0.9429 - val_accuracy: 0.6531\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.0299 - accuracy: 0.6525 - val_loss: 0.9337 - val_accuracy: 0.6837\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9804 - accuracy: 0.6500 - val_loss: 0.9432 - val_accuracy: 0.6480\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 1.0576 - accuracy: 0.6350 - val_loss: 0.9929 - val_accuracy: 0.6480\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9914 - accuracy: 0.6375 - val_loss: 1.0312 - val_accuracy: 0.6071\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9275 - accuracy: 0.6900 - val_loss: 0.9671 - val_accuracy: 0.6327\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1675 - accuracy: 0.6100 - val_loss: 0.8637 - val_accuracy: 0.6633\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0041 - accuracy: 0.6350 - val_loss: 1.2191 - val_accuracy: 0.6020\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0107 - accuracy: 0.6650 - val_loss: 0.8671 - val_accuracy: 0.6684\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0736 - accuracy: 0.6225 - val_loss: 0.8663 - val_accuracy: 0.6990\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9488 - accuracy: 0.6975 - val_loss: 0.7978 - val_accuracy: 0.7194\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1280 - accuracy: 0.6150 - val_loss: 1.1682 - val_accuracy: 0.5255\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0453 - accuracy: 0.6400 - val_loss: 0.8181 - val_accuracy: 0.6939\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0390 - accuracy: 0.6250 - val_loss: 0.9017 - val_accuracy: 0.6429\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0661 - accuracy: 0.6350 - val_loss: 0.8713 - val_accuracy: 0.6735\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0757 - accuracy: 0.6200 - val_loss: 0.8942 - val_accuracy: 0.6837\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9285 - accuracy: 0.6900 - val_loss: 0.9585 - val_accuracy: 0.6939\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.0612 - accuracy: 0.6125 - val_loss: 0.9351 - val_accuracy: 0.6888\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0928 - accuracy: 0.6375 - val_loss: 0.9577 - val_accuracy: 0.6888\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9576 - accuracy: 0.6825 - val_loss: 0.8645 - val_accuracy: 0.7041\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.9812 - accuracy: 0.6525 - val_loss: 0.9174 - val_accuracy: 0.6684\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0360 - accuracy: 0.6450 - val_loss: 0.8694 - val_accuracy: 0.6939\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1136 - accuracy: 0.5975 - val_loss: 0.8296 - val_accuracy: 0.7143\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9989 - accuracy: 0.6575 - val_loss: 0.9396 - val_accuracy: 0.6480\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.9689 - accuracy: 0.6550 - val_loss: 0.8290 - val_accuracy: 0.6939\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.1209 - accuracy: 0.5975 - val_loss: 0.8822 - val_accuracy: 0.6633\n",
      "Mouth Train Shape: (778, 2, 2, 512)\n",
      "Mouth Val Shape: (196, 2, 2, 512)\n",
      "Time training1:  0:26:00.885801\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 17s 81ms/step - loss: 2.0644 - accuracy: 0.2575 - val_loss: 1.4339 - val_accuracy: 0.4490\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.9648 - accuracy: 0.2925 - val_loss: 1.9104 - val_accuracy: 0.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.7191 - accuracy: 0.3300 - val_loss: 2.1793 - val_accuracy: 0.2551\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.6492 - accuracy: 0.3675 - val_loss: 1.4663 - val_accuracy: 0.4388\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.5083 - accuracy: 0.4250 - val_loss: 1.3744 - val_accuracy: 0.4490\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4591 - accuracy: 0.4800 - val_loss: 1.3091 - val_accuracy: 0.4694\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3607 - accuracy: 0.5025 - val_loss: 1.9076 - val_accuracy: 0.3571\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4008 - accuracy: 0.5275 - val_loss: 1.2715 - val_accuracy: 0.5255\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1845 - accuracy: 0.5775 - val_loss: 1.4080 - val_accuracy: 0.5204\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.1084 - accuracy: 0.6100 - val_loss: 1.0732 - val_accuracy: 0.6480\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.1837 - accuracy: 0.5575 - val_loss: 0.9243 - val_accuracy: 0.6939\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.0345 - accuracy: 0.6100 - val_loss: 1.0335 - val_accuracy: 0.5561\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 1.0694 - accuracy: 0.5875 - val_loss: 0.8328 - val_accuracy: 0.6429\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.8981 - accuracy: 0.6750 - val_loss: 0.8738 - val_accuracy: 0.6429\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.9060 - accuracy: 0.6900 - val_loss: 0.8039 - val_accuracy: 0.7092\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.6140 - accuracy: 0.6050 - val_loss: 0.9121 - val_accuracy: 0.6276\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.9719 - accuracy: 0.6675 - val_loss: 0.8982 - val_accuracy: 0.6378\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.8025 - accuracy: 0.6800 - val_loss: 0.8636 - val_accuracy: 0.6582\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.7955 - accuracy: 0.6725 - val_loss: 0.8525 - val_accuracy: 0.6633\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.8823 - accuracy: 0.7000 - val_loss: 0.7232 - val_accuracy: 0.7245\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.8647 - accuracy: 0.6550 - val_loss: 0.8271 - val_accuracy: 0.7347\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.7717 - accuracy: 0.6975 - val_loss: 0.6982 - val_accuracy: 0.7347\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.7128 - accuracy: 0.7075 - val_loss: 0.7784 - val_accuracy: 0.7398\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.7947 - accuracy: 0.7075 - val_loss: 0.7292 - val_accuracy: 0.7143\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.8009 - accuracy: 0.7250 - val_loss: 0.7679 - val_accuracy: 0.6786\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.8636 - accuracy: 0.6600 - val_loss: 0.7912 - val_accuracy: 0.6378\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.8589 - accuracy: 0.6850 - val_loss: 0.6168 - val_accuracy: 0.7755\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.7510 - accuracy: 0.7150 - val_loss: 0.5768 - val_accuracy: 0.7602\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.7726 - accuracy: 0.6850 - val_loss: 0.6493 - val_accuracy: 0.7908\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.7034 - accuracy: 0.7300 - val_loss: 0.6582 - val_accuracy: 0.7602\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.6844 - accuracy: 0.7575 - val_loss: 0.5528 - val_accuracy: 0.8112\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5884 - accuracy: 0.7625 - val_loss: 0.6105 - val_accuracy: 0.7857\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.7022 - accuracy: 0.7500 - val_loss: 0.7953 - val_accuracy: 0.7704\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.5831 - accuracy: 0.7950 - val_loss: 0.8006 - val_accuracy: 0.7194\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.6891 - accuracy: 0.7175 - val_loss: 0.5397 - val_accuracy: 0.7806\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.7433 - accuracy: 0.7300 - val_loss: 0.4940 - val_accuracy: 0.8520\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5465 - accuracy: 0.7950 - val_loss: 0.5480 - val_accuracy: 0.8112\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.7203 - accuracy: 0.7325 - val_loss: 0.5726 - val_accuracy: 0.7551\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.6429 - accuracy: 0.7500 - val_loss: 0.6991 - val_accuracy: 0.7041\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.7115 - accuracy: 0.7600 - val_loss: 0.5488 - val_accuracy: 0.7908\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5785 - accuracy: 0.8025 - val_loss: 0.5242 - val_accuracy: 0.8112\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.6069 - accuracy: 0.7700 - val_loss: 0.4861 - val_accuracy: 0.8163\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5951 - accuracy: 0.7900 - val_loss: 0.4048 - val_accuracy: 0.8571\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5531 - accuracy: 0.8125 - val_loss: 0.4443 - val_accuracy: 0.8061\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5224 - accuracy: 0.8050 - val_loss: 0.5007 - val_accuracy: 0.8061\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.5110 - accuracy: 0.8200 - val_loss: 0.5815 - val_accuracy: 0.8010\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.5390 - accuracy: 0.8125 - val_loss: 0.4242 - val_accuracy: 0.8418\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.4927 - accuracy: 0.8175 - val_loss: 0.4203 - val_accuracy: 0.8724\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.6026 - accuracy: 0.8125 - val_loss: 0.4142 - val_accuracy: 0.8112\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.5230 - accuracy: 0.8300 - val_loss: 0.3494 - val_accuracy: 0.8776\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5319 - accuracy: 0.8075 - val_loss: 0.4335 - val_accuracy: 0.8214\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5245 - accuracy: 0.8225 - val_loss: 0.4745 - val_accuracy: 0.8367\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.4726 - accuracy: 0.8300 - val_loss: 0.4563 - val_accuracy: 0.8163\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.6512 - accuracy: 0.7950 - val_loss: 0.6400 - val_accuracy: 0.7602\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.5991 - accuracy: 0.7875 - val_loss: 0.4284 - val_accuracy: 0.8367\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.5052 - accuracy: 0.8200 - val_loss: 0.4664 - val_accuracy: 0.8520\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 15s 75ms/step - loss: 0.6172 - accuracy: 0.8625 - val_loss: 0.4770 - val_accuracy: 0.8265\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.6539 - accuracy: 0.7775 - val_loss: 0.4044 - val_accuracy: 0.8367\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.6450 - accuracy: 0.7900 - val_loss: 0.3996 - val_accuracy: 0.8469\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.5051 - accuracy: 0.8250 - val_loss: 0.3984 - val_accuracy: 0.8776\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.4955 - accuracy: 0.8400 - val_loss: 0.5158 - val_accuracy: 0.8061\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.5584 - accuracy: 0.8225 - val_loss: 0.3256 - val_accuracy: 0.8776\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.5049 - accuracy: 0.8300 - val_loss: 0.3913 - val_accuracy: 0.8367\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.5006 - accuracy: 0.8200 - val_loss: 0.3130 - val_accuracy: 0.8622\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.4676 - accuracy: 0.8325 - val_loss: 0.3591 - val_accuracy: 0.8724\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.6185 - accuracy: 0.8125 - val_loss: 0.4612 - val_accuracy: 0.8469\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.4685 - accuracy: 0.8550 - val_loss: 0.3921 - val_accuracy: 0.8622\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.4541 - accuracy: 0.8575 - val_loss: 0.3543 - val_accuracy: 0.8776\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.5673 - accuracy: 0.8225 - val_loss: 0.3327 - val_accuracy: 0.8724\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.4060 - accuracy: 0.8800 - val_loss: 0.4280 - val_accuracy: 0.8316\n",
      "LeftEye Train Shape: (778, 2, 2, 512)\n",
      "LeftEye Val Shape: (196, 2, 2, 512)\n",
      "Time training2:  0:18:17.099589\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 2.0953 - accuracy: 0.2400 - val_loss: 1.8783 - val_accuracy: 0.2551\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.9241 - accuracy: 0.2650 - val_loss: 1.8885 - val_accuracy: 0.2704\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.9134 - accuracy: 0.1825 - val_loss: 1.8651 - val_accuracy: 0.2551\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8293 - accuracy: 0.2650 - val_loss: 1.8330 - val_accuracy: 0.2551\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8205 - accuracy: 0.2800 - val_loss: 1.8295 - val_accuracy: 0.2551\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8656 - accuracy: 0.2650 - val_loss: 1.8336 - val_accuracy: 0.2551\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8740 - accuracy: 0.2300 - val_loss: 1.8336 - val_accuracy: 0.2551\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8225 - accuracy: 0.2750 - val_loss: 1.8285 - val_accuracy: 0.2551\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8409 - accuracy: 0.2250 - val_loss: 1.8302 - val_accuracy: 0.2551\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8342 - accuracy: 0.2650 - val_loss: 1.8285 - val_accuracy: 0.2551\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8282 - accuracy: 0.2025 - val_loss: 1.8293 - val_accuracy: 0.2551\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8615 - accuracy: 0.2600 - val_loss: 1.8303 - val_accuracy: 0.2551\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8200 - accuracy: 0.2450 - val_loss: 1.8281 - val_accuracy: 0.2551\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8562 - accuracy: 0.2400 - val_loss: 1.8291 - val_accuracy: 0.2551\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8653 - accuracy: 0.2500 - val_loss: 1.8302 - val_accuracy: 0.2551\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8253 - accuracy: 0.2600 - val_loss: 1.8291 - val_accuracy: 0.2551\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8398 - accuracy: 0.2200 - val_loss: 1.8309 - val_accuracy: 0.2092\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.8333 - accuracy: 0.2625 - val_loss: 1.8288 - val_accuracy: 0.2551\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8068 - accuracy: 0.2350 - val_loss: 1.8294 - val_accuracy: 0.2551\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8576 - accuracy: 0.2475 - val_loss: 1.8287 - val_accuracy: 0.2551\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8318 - accuracy: 0.2550 - val_loss: 1.8281 - val_accuracy: 0.2551\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8792 - accuracy: 0.2300 - val_loss: 1.8328 - val_accuracy: 0.2551\n",
      "RightEye Train Shape: (778, 2, 2, 512)\n",
      "RightEye Val Shape: (196, 2, 2, 512)\n",
      "Time training3:  0:06:04.199979\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 17s 81ms/step - loss: 2.0652 - accuracy: 0.2350 - val_loss: 1.8718 - val_accuracy: 0.2092\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8455 - accuracy: 0.2350 - val_loss: 1.8365 - val_accuracy: 0.2092\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8516 - accuracy: 0.2525 - val_loss: 1.8296 - val_accuracy: 0.2551\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8599 - accuracy: 0.2500 - val_loss: 1.8321 - val_accuracy: 0.2551\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8067 - accuracy: 0.2800 - val_loss: 1.8309 - val_accuracy: 0.2551\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8523 - accuracy: 0.2600 - val_loss: 1.8306 - val_accuracy: 0.2551\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8323 - accuracy: 0.2350 - val_loss: 1.8299 - val_accuracy: 0.2551\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8523 - accuracy: 0.2650 - val_loss: 1.8320 - val_accuracy: 0.2551\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.7964 - accuracy: 0.2850 - val_loss: 1.8296 - val_accuracy: 0.2551\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8009 - accuracy: 0.2750 - val_loss: 1.8289 - val_accuracy: 0.2551\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8591 - accuracy: 0.2650 - val_loss: 1.8281 - val_accuracy: 0.2551\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8643 - accuracy: 0.2500 - val_loss: 1.8290 - val_accuracy: 0.2551\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.8690 - accuracy: 0.2400 - val_loss: 1.8305 - val_accuracy: 0.2551\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8252 - accuracy: 0.2550 - val_loss: 1.8272 - val_accuracy: 0.2551\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.7991 - accuracy: 0.2550 - val_loss: 1.8322 - val_accuracy: 0.2551\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8160 - accuracy: 0.2175 - val_loss: 1.8300 - val_accuracy: 0.2551\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8625 - accuracy: 0.2400 - val_loss: 1.8284 - val_accuracy: 0.2551\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8708 - accuracy: 0.2500 - val_loss: 1.8321 - val_accuracy: 0.2551\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8457 - accuracy: 0.2250 - val_loss: 1.8297 - val_accuracy: 0.2551\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8655 - accuracy: 0.2350 - val_loss: 1.8299 - val_accuracy: 0.2551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8443 - accuracy: 0.2600 - val_loss: 1.8284 - val_accuracy: 0.2551\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.9738 - accuracy: 0.2575 - val_loss: 7.8877 - val_accuracy: 0.2551\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 2.0944 - accuracy: 0.2100 - val_loss: 1.8255 - val_accuracy: 0.3622\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.9123 - accuracy: 0.2250 - val_loss: 1.8491 - val_accuracy: 0.2551\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8512 - accuracy: 0.2425 - val_loss: 1.8031 - val_accuracy: 0.2551\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.8440 - accuracy: 0.3475 - val_loss: 1.6026 - val_accuracy: 0.4337\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.7577 - accuracy: 0.3825 - val_loss: 1.6515 - val_accuracy: 0.3673\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.6500 - accuracy: 0.3925 - val_loss: 1.4405 - val_accuracy: 0.4082\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4959 - accuracy: 0.3975 - val_loss: 1.6106 - val_accuracy: 0.3980\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.5745 - accuracy: 0.3625 - val_loss: 1.4836 - val_accuracy: 0.4286\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4969 - accuracy: 0.4525 - val_loss: 1.4842 - val_accuracy: 0.4082\n",
      "Epoch 32/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.5334 - accuracy: 0.3725 - val_loss: 1.4601 - val_accuracy: 0.4082\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.5210 - accuracy: 0.4250 - val_loss: 1.3733 - val_accuracy: 0.4388\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3980 - accuracy: 0.4450 - val_loss: 1.3270 - val_accuracy: 0.4235\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4422 - accuracy: 0.4500 - val_loss: 1.3639 - val_accuracy: 0.4184\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.5174 - accuracy: 0.4125 - val_loss: 1.3402 - val_accuracy: 0.4439\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4185 - accuracy: 0.4425 - val_loss: 1.3254 - val_accuracy: 0.4592\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4183 - accuracy: 0.4450 - val_loss: 1.3086 - val_accuracy: 0.4541\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3862 - accuracy: 0.4400 - val_loss: 1.2993 - val_accuracy: 0.4745\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3859 - accuracy: 0.4325 - val_loss: 1.2941 - val_accuracy: 0.4796\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3216 - accuracy: 0.4750 - val_loss: 1.3134 - val_accuracy: 0.4184\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3847 - accuracy: 0.4525 - val_loss: 1.3185 - val_accuracy: 0.4439\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3568 - accuracy: 0.4750 - val_loss: 1.3107 - val_accuracy: 0.4643\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4264 - accuracy: 0.4500 - val_loss: 1.3433 - val_accuracy: 0.4286\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.4262 - accuracy: 0.4350 - val_loss: 1.4048 - val_accuracy: 0.4388\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3752 - accuracy: 0.4500 - val_loss: 1.2829 - val_accuracy: 0.4643\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3484 - accuracy: 0.4475 - val_loss: 1.4254 - val_accuracy: 0.4337\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.3434 - accuracy: 0.5050 - val_loss: 1.3512 - val_accuracy: 0.4898\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3106 - accuracy: 0.4750 - val_loss: 1.3356 - val_accuracy: 0.4949\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3481 - accuracy: 0.4450 - val_loss: 1.3040 - val_accuracy: 0.4694\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3046 - accuracy: 0.4800 - val_loss: 1.2585 - val_accuracy: 0.4847\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3276 - accuracy: 0.4750 - val_loss: 1.3013 - val_accuracy: 0.5102\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.2392 - accuracy: 0.5375 - val_loss: 1.2489 - val_accuracy: 0.5255\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.2554 - accuracy: 0.5450 - val_loss: 1.2647 - val_accuracy: 0.5663\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 1.3150 - accuracy: 0.5000 - val_loss: 1.2416 - val_accuracy: 0.5357\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 1.2547 - accuracy: 0.5250 - val_loss: 1.2090 - val_accuracy: 0.5357\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.2767 - accuracy: 0.5350 - val_loss: 1.3212 - val_accuracy: 0.4847\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.5057 - accuracy: 0.5075 - val_loss: 1.3116 - val_accuracy: 0.5102\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.2751 - accuracy: 0.5350 - val_loss: 1.2453 - val_accuracy: 0.5765\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.3686 - accuracy: 0.5100 - val_loss: 1.2004 - val_accuracy: 0.5510\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2572 - accuracy: 0.5400 - val_loss: 1.3532 - val_accuracy: 0.4643\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2048 - accuracy: 0.5150 - val_loss: 1.1737 - val_accuracy: 0.5510\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2970 - accuracy: 0.4900 - val_loss: 1.3249 - val_accuracy: 0.4898\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2601 - accuracy: 0.5425 - val_loss: 1.1739 - val_accuracy: 0.5408\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2315 - accuracy: 0.5250 - val_loss: 1.2149 - val_accuracy: 0.5867\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.2681 - accuracy: 0.5275 - val_loss: 1.1782 - val_accuracy: 0.5765\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.3319 - accuracy: 0.4875 - val_loss: 1.1486 - val_accuracy: 0.5714\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1360 - accuracy: 0.5750 - val_loss: 1.1480 - val_accuracy: 0.5816\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1920 - accuracy: 0.5625 - val_loss: 1.3115 - val_accuracy: 0.4847\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2642 - accuracy: 0.5375 - val_loss: 1.1866 - val_accuracy: 0.5612\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1800 - accuracy: 0.5775 - val_loss: 1.2507 - val_accuracy: 0.5561\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1417 - accuracy: 0.6100 - val_loss: 1.2725 - val_accuracy: 0.5102\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1566 - accuracy: 0.6100 - val_loss: 1.2778 - val_accuracy: 0.5408\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.2475 - accuracy: 0.5550 - val_loss: 1.1568 - val_accuracy: 0.6020\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.2302 - accuracy: 0.5525 - val_loss: 1.1953 - val_accuracy: 0.5408\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2007 - accuracy: 0.5575 - val_loss: 1.1845 - val_accuracy: 0.5816\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1959 - accuracy: 0.5700 - val_loss: 1.2119 - val_accuracy: 0.5663\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2238 - accuracy: 0.5650 - val_loss: 1.2141 - val_accuracy: 0.5510\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.2649 - accuracy: 0.5575 - val_loss: 1.1078 - val_accuracy: 0.5918\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2439 - accuracy: 0.5775 - val_loss: 1.1330 - val_accuracy: 0.5867\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.2164 - accuracy: 0.5625 - val_loss: 1.1276 - val_accuracy: 0.5969\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1833 - accuracy: 0.5925 - val_loss: 1.1997 - val_accuracy: 0.5612\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.1255 - accuracy: 0.6200 - val_loss: 1.0951 - val_accuracy: 0.6122\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1291 - accuracy: 0.5925 - val_loss: 1.1689 - val_accuracy: 0.5816\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1740 - accuracy: 0.5825 - val_loss: 1.1470 - val_accuracy: 0.5663\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2444 - accuracy: 0.5750 - val_loss: 1.1513 - val_accuracy: 0.5765\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.2037 - accuracy: 0.5550 - val_loss: 1.1203 - val_accuracy: 0.5816\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1495 - accuracy: 0.6000 - val_loss: 1.0989 - val_accuracy: 0.6276\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.1942 - accuracy: 0.5750 - val_loss: 1.1501 - val_accuracy: 0.5867\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1560 - accuracy: 0.5750 - val_loss: 1.2649 - val_accuracy: 0.5510\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1530 - accuracy: 0.5525 - val_loss: 1.2726 - val_accuracy: 0.5612\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.3189 - accuracy: 0.5200 - val_loss: 1.1239 - val_accuracy: 0.6020\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2073 - accuracy: 0.5550 - val_loss: 1.1070 - val_accuracy: 0.6122\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1361 - accuracy: 0.5875 - val_loss: 1.1275 - val_accuracy: 0.6122\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1644 - accuracy: 0.5800 - val_loss: 1.1573 - val_accuracy: 0.5714\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1387 - accuracy: 0.5850 - val_loss: 1.1323 - val_accuracy: 0.6224\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2057 - accuracy: 0.5950 - val_loss: 1.1962 - val_accuracy: 0.5765\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1904 - accuracy: 0.5675 - val_loss: 1.1082 - val_accuracy: 0.6122\n",
      "Epoch 99/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.1485 - accuracy: 0.5575 - val_loss: 1.1919 - val_accuracy: 0.5714\n",
      "Epoch 100/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0838 - accuracy: 0.5975 - val_loss: 1.1627 - val_accuracy: 0.6020\n",
      "Nose Train Shape: (778, 2, 2, 512)\n",
      "Nose Val Shape: (196, 2, 2, 512)\n",
      "Time training4:  0:26:34.391000\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Epoch 1/100\n",
      "200/200 [==============================] - 19s 89ms/step - loss: 2.1000 - accuracy: 0.2550 - val_loss: 1.7720 - val_accuracy: 0.2602\n",
      "Epoch 2/100\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 1.8863 - accuracy: 0.2575 - val_loss: 1.7910 - val_accuracy: 0.3673\n",
      "Epoch 3/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.8720 - accuracy: 0.2675 - val_loss: 1.9204 - val_accuracy: 0.2092\n",
      "Epoch 4/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.7891 - accuracy: 0.3625 - val_loss: 1.4860 - val_accuracy: 0.4184\n",
      "Epoch 5/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.6747 - accuracy: 0.3525 - val_loss: 1.4873 - val_accuracy: 0.4235\n",
      "Epoch 6/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.7253 - accuracy: 0.3225 - val_loss: 1.4231 - val_accuracy: 0.3724\n",
      "Epoch 7/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.5767 - accuracy: 0.4250 - val_loss: 1.4902 - val_accuracy: 0.5051\n",
      "Epoch 8/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.5587 - accuracy: 0.4125 - val_loss: 1.3634 - val_accuracy: 0.4847\n",
      "Epoch 9/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.5908 - accuracy: 0.4350 - val_loss: 1.4277 - val_accuracy: 0.5408\n",
      "Epoch 10/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.5690 - accuracy: 0.4075 - val_loss: 1.3820 - val_accuracy: 0.4082\n",
      "Epoch 11/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.7079 - accuracy: 0.3675 - val_loss: 1.4724 - val_accuracy: 0.4694\n",
      "Epoch 12/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.4205 - accuracy: 0.4675 - val_loss: 1.3454 - val_accuracy: 0.5459\n",
      "Epoch 13/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.4504 - accuracy: 0.4775 - val_loss: 1.4007 - val_accuracy: 0.4898\n",
      "Epoch 14/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.4637 - accuracy: 0.4875 - val_loss: 1.4076 - val_accuracy: 0.4949\n",
      "Epoch 15/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.4102 - accuracy: 0.4700 - val_loss: 1.2795 - val_accuracy: 0.5051\n",
      "Epoch 16/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.3228 - accuracy: 0.5025 - val_loss: 1.3058 - val_accuracy: 0.5306\n",
      "Epoch 17/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.4170 - accuracy: 0.4525 - val_loss: 1.3248 - val_accuracy: 0.5153\n",
      "Epoch 18/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.4513 - accuracy: 0.4575 - val_loss: 1.4641 - val_accuracy: 0.4133\n",
      "Epoch 19/100\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 1.4297 - accuracy: 0.4625 - val_loss: 1.3747 - val_accuracy: 0.4796\n",
      "Epoch 20/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.3033 - accuracy: 0.5200 - val_loss: 1.3445 - val_accuracy: 0.5255\n",
      "Epoch 21/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.3566 - accuracy: 0.5025 - val_loss: 1.4084 - val_accuracy: 0.4643\n",
      "Epoch 22/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.3819 - accuracy: 0.5025 - val_loss: 1.5686 - val_accuracy: 0.4949\n",
      "Epoch 23/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.4491 - accuracy: 0.5125 - val_loss: 1.2160 - val_accuracy: 0.5408\n",
      "Epoch 24/100\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 1.3764 - accuracy: 0.5100 - val_loss: 1.3776 - val_accuracy: 0.4949\n",
      "Epoch 25/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.3496 - accuracy: 0.4850 - val_loss: 1.3021 - val_accuracy: 0.5153\n",
      "Epoch 26/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.3156 - accuracy: 0.5175 - val_loss: 1.1625 - val_accuracy: 0.5459\n",
      "Epoch 27/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.2305 - accuracy: 0.5450 - val_loss: 1.1969 - val_accuracy: 0.5306\n",
      "Epoch 28/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.3393 - accuracy: 0.5300 - val_loss: 1.4673 - val_accuracy: 0.4337\n",
      "Epoch 29/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.2713 - accuracy: 0.5150 - val_loss: 1.1838 - val_accuracy: 0.5357\n",
      "Epoch 30/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.2866 - accuracy: 0.5250 - val_loss: 1.1952 - val_accuracy: 0.5663\n",
      "Epoch 31/100\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 1.2364 - accuracy: 0.5125 - val_loss: 1.2363 - val_accuracy: 0.5408\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1836 - accuracy: 0.5250 - val_loss: 1.2212 - val_accuracy: 0.5357\n",
      "Epoch 33/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2326 - accuracy: 0.4925 - val_loss: 1.8655 - val_accuracy: 0.4184\n",
      "Epoch 34/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.2186 - accuracy: 0.5475 - val_loss: 1.0698 - val_accuracy: 0.5663\n",
      "Epoch 35/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1229 - accuracy: 0.5850 - val_loss: 1.0454 - val_accuracy: 0.5867\n",
      "Epoch 36/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.1898 - accuracy: 0.5375 - val_loss: 1.2472 - val_accuracy: 0.5816\n",
      "Epoch 37/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1954 - accuracy: 0.5825 - val_loss: 1.1561 - val_accuracy: 0.5765\n",
      "Epoch 38/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1733 - accuracy: 0.5600 - val_loss: 1.1461 - val_accuracy: 0.5510\n",
      "Epoch 39/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.1833 - accuracy: 0.5625 - val_loss: 1.1003 - val_accuracy: 0.5306\n",
      "Epoch 40/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2040 - accuracy: 0.5225 - val_loss: 1.1675 - val_accuracy: 0.5204\n",
      "Epoch 41/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2164 - accuracy: 0.5675 - val_loss: 1.1295 - val_accuracy: 0.5510\n",
      "Epoch 42/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1665 - accuracy: 0.5800 - val_loss: 1.3469 - val_accuracy: 0.5204\n",
      "Epoch 43/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.1853 - accuracy: 0.5850 - val_loss: 1.2420 - val_accuracy: 0.5765\n",
      "Epoch 44/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.2097 - accuracy: 0.5400 - val_loss: 1.1073 - val_accuracy: 0.6071\n",
      "Epoch 45/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.0590 - accuracy: 0.6050 - val_loss: 1.4794 - val_accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.1245 - accuracy: 0.6025 - val_loss: 1.1714 - val_accuracy: 0.5816\n",
      "Epoch 47/100\n",
      "200/200 [==============================] - 16s 83ms/step - loss: 1.1233 - accuracy: 0.5850 - val_loss: 2.6654 - val_accuracy: 0.4745\n",
      "Epoch 48/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.1238 - accuracy: 0.6175 - val_loss: 1.0437 - val_accuracy: 0.5765\n",
      "Epoch 49/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.0542 - accuracy: 0.6100 - val_loss: 1.1814 - val_accuracy: 0.5918\n",
      "Epoch 50/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.1639 - accuracy: 0.5600 - val_loss: 1.1150 - val_accuracy: 0.5459\n",
      "Epoch 51/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.0828 - accuracy: 0.6100 - val_loss: 1.1027 - val_accuracy: 0.5969\n",
      "Epoch 52/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.1761 - accuracy: 0.5950 - val_loss: 1.8432 - val_accuracy: 0.4286\n",
      "Epoch 53/100\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 1.1969 - accuracy: 0.5950 - val_loss: 1.2825 - val_accuracy: 0.5714\n",
      "Epoch 54/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1585 - accuracy: 0.5825 - val_loss: 1.1493 - val_accuracy: 0.5714\n",
      "Epoch 55/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0426 - accuracy: 0.6600 - val_loss: 1.0485 - val_accuracy: 0.6071\n",
      "Epoch 56/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0377 - accuracy: 0.6200 - val_loss: 1.1258 - val_accuracy: 0.5918\n",
      "Epoch 57/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.3910 - accuracy: 0.5100 - val_loss: 1.2640 - val_accuracy: 0.5459\n",
      "Epoch 58/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1762 - accuracy: 0.5225 - val_loss: 1.0572 - val_accuracy: 0.6480\n",
      "Epoch 59/100\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 1.1284 - accuracy: 0.5900 - val_loss: 1.2238 - val_accuracy: 0.5510\n",
      "Epoch 60/100\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 1.0204 - accuracy: 0.6175 - val_loss: 1.0153 - val_accuracy: 0.6684\n",
      "Epoch 61/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.0810 - accuracy: 0.5825 - val_loss: 1.0465 - val_accuracy: 0.6378\n",
      "Epoch 62/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.0560 - accuracy: 0.6075 - val_loss: 1.0100 - val_accuracy: 0.6888\n",
      "Epoch 63/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.1236 - accuracy: 0.5825 - val_loss: 1.0243 - val_accuracy: 0.6582\n",
      "Epoch 64/100\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 1.0158 - accuracy: 0.6250 - val_loss: 0.9992 - val_accuracy: 0.6122\n",
      "Epoch 65/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0747 - accuracy: 0.6175 - val_loss: 1.0744 - val_accuracy: 0.6378\n",
      "Epoch 66/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.0556 - accuracy: 0.5900 - val_loss: 1.1438 - val_accuracy: 0.6173\n",
      "Epoch 67/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0894 - accuracy: 0.6250 - val_loss: 0.9743 - val_accuracy: 0.6531\n",
      "Epoch 68/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0974 - accuracy: 0.6075 - val_loss: 0.9767 - val_accuracy: 0.6429\n",
      "Epoch 69/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0778 - accuracy: 0.5950 - val_loss: 0.9889 - val_accuracy: 0.6480\n",
      "Epoch 70/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.0917 - accuracy: 0.6175 - val_loss: 0.9749 - val_accuracy: 0.6480\n",
      "Epoch 71/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.0257 - accuracy: 0.6300 - val_loss: 0.8680 - val_accuracy: 0.6837\n",
      "Epoch 72/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.9869 - accuracy: 0.6375 - val_loss: 0.9434 - val_accuracy: 0.6786\n",
      "Epoch 73/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.0881 - accuracy: 0.6275 - val_loss: 0.8643 - val_accuracy: 0.6888\n",
      "Epoch 74/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.0078 - accuracy: 0.6225 - val_loss: 1.3753 - val_accuracy: 0.5459\n",
      "Epoch 75/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0722 - accuracy: 0.6750 - val_loss: 1.0325 - val_accuracy: 0.6939\n",
      "Epoch 76/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.1380 - accuracy: 0.5925 - val_loss: 1.0090 - val_accuracy: 0.6633\n",
      "Epoch 77/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.9791 - accuracy: 0.6525 - val_loss: 0.9276 - val_accuracy: 0.6327\n",
      "Epoch 78/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.1147 - accuracy: 0.6050 - val_loss: 0.8991 - val_accuracy: 0.7194\n",
      "Epoch 79/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.0038 - accuracy: 0.6475 - val_loss: 0.8431 - val_accuracy: 0.7092\n",
      "Epoch 80/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.9863 - accuracy: 0.6675 - val_loss: 0.8708 - val_accuracy: 0.6786\n",
      "Epoch 81/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0786 - accuracy: 0.6300 - val_loss: 1.0233 - val_accuracy: 0.6480\n",
      "Epoch 82/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.2997 - accuracy: 0.5825 - val_loss: 0.9290 - val_accuracy: 0.6939\n",
      "Epoch 83/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0865 - accuracy: 0.6075 - val_loss: 1.0014 - val_accuracy: 0.6582\n",
      "Epoch 84/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.9342 - accuracy: 0.6400 - val_loss: 1.1271 - val_accuracy: 0.6224\n",
      "Epoch 85/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.0209 - accuracy: 0.6325 - val_loss: 0.9698 - val_accuracy: 0.6786\n",
      "Epoch 86/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 0.9905 - accuracy: 0.6425 - val_loss: 0.9735 - val_accuracy: 0.6990\n",
      "Epoch 87/100\n",
      "200/200 [==============================] - 16s 80ms/step - loss: 1.0088 - accuracy: 0.6100 - val_loss: 0.8769 - val_accuracy: 0.6990\n",
      "Epoch 88/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.9596 - accuracy: 0.6400 - val_loss: 0.9082 - val_accuracy: 0.6429\n",
      "Epoch 89/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.9438 - accuracy: 0.6675 - val_loss: 0.9608 - val_accuracy: 0.6582\n",
      "Epoch 90/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.0044 - accuracy: 0.6550 - val_loss: 0.8759 - val_accuracy: 0.6735\n",
      "Epoch 91/100\n",
      "200/200 [==============================] - 17s 84ms/step - loss: 0.9792 - accuracy: 0.6400 - val_loss: 0.8696 - val_accuracy: 0.6888\n",
      "Epoch 92/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.9064 - accuracy: 0.6875 - val_loss: 1.5655 - val_accuracy: 0.4694\n",
      "Epoch 93/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 1.0074 - accuracy: 0.6150 - val_loss: 0.9042 - val_accuracy: 0.6531\n",
      "Epoch 94/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.8850 - accuracy: 0.6675 - val_loss: 1.0893 - val_accuracy: 0.6480\n",
      "Epoch 95/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.9819 - accuracy: 0.6575 - val_loss: 1.1062 - val_accuracy: 0.6327\n",
      "Epoch 96/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.0835 - accuracy: 0.6525 - val_loss: 0.9742 - val_accuracy: 0.6786\n",
      "Epoch 97/100\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.9928 - accuracy: 0.6425 - val_loss: 0.9432 - val_accuracy: 0.6531\n",
      "Epoch 98/100\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 0.9846 - accuracy: 0.6400 - val_loss: 1.1388 - val_accuracy: 0.6173\n",
      "Forehead Train Shape: (778, 2, 2, 512)\n",
      "Forehead Val Shape: (196, 2, 2, 512)\n",
      "Time training5:  0:26:56.814661\n"
     ]
    }
   ],
   "source": [
    "for dataset in tq.tqdm(range(6)):\n",
    "    \n",
    "    DATASET_NAMES = [\"fullImage\",\"Mouth\",\"LeftEye\",\"RightEye\",\"Nose\",\"Forehead\"]\n",
    "    train_data_dir = r'FinalMultiFer2013/Dataset{}/train'.format(dataset)\n",
    "    val_data_dir = r'FinalMultiFer2013/Dataset{}/val'.format(dataset)\n",
    "    start = datetime.datetime.now()\n",
    "    \n",
    "    # Loading Data\n",
    "    train_Datagenerator = ImageDataGenerator(rotation_range=20,\n",
    "                                             rescale=1./255,\n",
    "                                             shear_range=0.1,\n",
    "                                             zoom_range=0.2,\n",
    "                                             horizontal_flip=True,\n",
    "                                             width_shift_range=0.1,\n",
    "                                             height_shift_range=0.1) \n",
    "    \n",
    "    val_Datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    generator_train = train_Datagenerator.flow_from_directory(train_data_dir,\n",
    "                                                  target_size=(img_width, img_height),\n",
    "                                                  batch_size=batch_size, \n",
    "                                                  class_mode='categorical',\n",
    "                                                  seed = 2, \n",
    "                                                  shuffle=False)\n",
    "    \n",
    "    generator_val = val_Datagenerator.flow_from_directory(val_data_dir, \n",
    "                                                target_size=(img_width, img_height), \n",
    "                                                batch_size=batch_size, class_mode='categorical', \n",
    "                                                shuffle=False)\n",
    "\n",
    "    \n",
    "    # Create custom VGG16 Model\n",
    "    base_model = applications.VGG16(include_top=False, \n",
    "                               weights='imagenet',\n",
    "                               input_shape=generator_train.image_shape)\n",
    "    \n",
    "    for layer in base_model.layers[:15]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    \n",
    "    \"\"\"modelTemp = Sequential()\n",
    "    for layer in base_model.layers[:-1]:\n",
    "        modelTemp.add(layer)\n",
    "    base_model = modelTemp\"\"\"\n",
    "\n",
    "    # Classifier\n",
    "    flatten_layer = layers.Flatten()\n",
    "    dense_layer_1 = layers.Dense(512, activation='relu')\n",
    "    drop_out_1 = layers.Dropout(0.3)\n",
    "    dense_layer_2 = layers.Dense(256, activation='relu')\n",
    "    drop_out_2 = layers.Dropout(0.3)\n",
    "    dense_layer_3 = layers.Dense(100, activation='relu')\n",
    "    prediction_layer = layers.Dense(7, activation='softmax')\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        flatten_layer,\n",
    "        dense_layer_1,\n",
    "        drop_out_1,\n",
    "        # dense_layer_2,\n",
    "        # drop_out_2,\n",
    "        dense_layer_3,\n",
    "        prediction_layer\n",
    "    ])\n",
    "\n",
    "    # Compile and Fit\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'],\n",
    "    )\n",
    "\n",
    "    es = EarlyStopping(monitor='val_accuracy', mode='max', \n",
    "                       patience=20,  restore_best_weights=True)\n",
    "\n",
    "    history = model.fit(generator_train,\n",
    "                        validation_data=generator_val, \n",
    "                        steps_per_epoch=200, \n",
    "                        epochs=100,\n",
    "                        batch_size=2,\n",
    "                        callbacks=[es])\n",
    "\n",
    "    # Predict and Save Features\n",
    "    nb_train_samples = len(generator_train.filenames) \n",
    "    num_classes = len(generator_train.class_indices)\n",
    "\n",
    "    nb_val_samples = len(generator_val.filenames) \n",
    "    num_classes = len(generator_val.class_indices)  \n",
    "\n",
    "    predict_size_train = int(math.ceil(nb_train_samples / batch_size)) \n",
    "    predict_size_val = int(math.ceil(nb_train_samples / batch_size)) \n",
    "\n",
    "    dataset_features_train = model.layers[0].predict(generator_train, predict_size_train) \n",
    "    dataset_features_valid = model.layers[0].predict(generator_val, predict_size_val)\n",
    "\n",
    "    BOTTLENECK_SAVE_PATH_Train = r'FerModels/train/{}_bottleneck_features.npy'.format(DATASET_NAMES[dataset])\n",
    "    BOTTLENECK_SAVE_PATH_Val = r'FerModels/val/{}_bottleneck_features.npy'.format(DATASET_NAMES[dataset])\n",
    "    np.save(BOTTLENECK_SAVE_PATH_Train, dataset_features_train)\n",
    "    np.save(BOTTLENECK_SAVE_PATH_Val, dataset_features_valid)\n",
    "\n",
    "    print(DATASET_NAMES[dataset], \"Train\",\"Shape: {}\".format(dataset_features_train.shape))\n",
    "    print(DATASET_NAMES[dataset], \"Val\",\"Shape: {}\".format(dataset_features_valid.shape))\n",
    "    end = datetime.datetime.now()\n",
    "    elapsed= end-start\n",
    "    print (f'Time training{dataset}: ', elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550b50f",
   "metadata": {
    "id": "9550b50f"
   },
   "source": [
    "### Stacking all BottleNeck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caf4ffc2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "caf4ffc2",
    "outputId": "a90dcd58-c80d-4fbf-b8ce-f5d6f0d2889f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n",
      "Found 778 images belonging to 7 classes.\n",
      "Found 196 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Appending all bottle neck features to a single list \n",
    "\n",
    "FEATURES_STACK_TRAINX = []\n",
    "FEATURES_STACK_VALX = []\n",
    "FEATURES_STACK_TRAINY = []\n",
    "FEATURES_STACK_VALY = []\n",
    "DATASET_NAMES = [\"fullImage\",\"Nose\",\"Mouth\",\"LeftEye\",\"RightEye\",\"Forehead\"]\n",
    "# DATASET_NAMES = [\"fullImage\"] # for Single \n",
    "TRAIN_VAL = [\"train\",\"val\"]\n",
    "\n",
    "Datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "for i in range(len(DATASET_NAMES)):\n",
    "    for j in TRAIN_VAL:\n",
    "        data_dir = r'FinalMultiCK+/Dataset{}/{}'.format(i,j)\n",
    "        generator = Datagenerator.flow_from_directory(data_dir, \n",
    "                                                target_size=(img_width, img_height),\n",
    "                                                batch_size=batch_size, \n",
    "                                                class_mode='categorical', \n",
    "                                                shuffle=False) \n",
    "\n",
    "        nb_train_samples = len(generator.filenames) \n",
    "        num_classes = len(generator.class_indices) \n",
    "\n",
    "        data = np.load(r'CKModels/{}/{}_bottleneck_features.npy'.format(j,DATASET_NAMES[i])) \n",
    "        labels = generator.classes \n",
    "        labels = to_categorical(labels, num_classes=num_classes)\n",
    "        \n",
    "        if j in \"val\":\n",
    "            FEATURES_STACK_VALX.append(data) \n",
    "            FEATURES_STACK_VALY.append(labels)\n",
    "        else:\n",
    "            FEATURES_STACK_TRAINX.append(data)\n",
    "            FEATURES_STACK_TRAINY.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "975ce664",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "975ce664",
    "outputId": "59747a3a-0a48-4b39-d5af-066cf5cfece5"
   },
   "outputs": [],
   "source": [
    "# Stacking them all together\n",
    "STACKED_FEATURES_TRAINX = FEATURES_STACK_TRAINX[0]\n",
    "for FEATURES in FEATURES_STACK_TRAINX[1:]:\n",
    "    STACKED_FEATURES_TRAINX = np.concatenate((STACKED_FEATURES_TRAINX,FEATURES),axis=3)\n",
    "    \n",
    "STACKED_FEATURES_VALX = FEATURES_STACK_VALX[0]\n",
    "for FEATURES in FEATURES_STACK_VALX[1:]:\n",
    "    STACKED_FEATURES_VALX = np.concatenate((STACKED_FEATURES_VALX,FEATURES),axis=3)\n",
    "    \n",
    "STACKED_FEATURES_TRAINY = FEATURES_STACK_TRAINY[0]\n",
    "    \n",
    "STACKED_FEATURES_VALY = FEATURES_STACK_VALY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1bc2f4a",
   "metadata": {
    "id": "e1bc2f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape X:  (778, 2, 2, 3072)\n",
      "Train shape Y:  (778, 7)\n",
      "Val shape X:  (196, 2, 2, 3072)\n",
      "Val shape Y:  (196, 7)\n"
     ]
    }
   ],
   "source": [
    "# Final Shapes\n",
    "print(\"Train shape X: \",STACKED_FEATURES_TRAINX.shape)\n",
    "print(\"Train shape Y: \",STACKED_FEATURES_TRAINY.shape)\n",
    "print(\"Val shape X: \",STACKED_FEATURES_VALX.shape)\n",
    "print(\"Val shape Y: \",STACKED_FEATURES_VALY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "78450ccc",
   "metadata": {
    "id": "78450ccc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "25/25 [==============================] - 1s 30ms/step - loss: 1.0542 - acc: 0.6337 - val_loss: 0.3097 - val_acc: 0.9439\n",
      "Epoch 2/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.4009 - acc: 0.8625 - val_loss: 0.1439 - val_acc: 0.9796\n",
      "Epoch 3/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.3277 - acc: 0.8882 - val_loss: 0.1068 - val_acc: 0.9745\n",
      "Epoch 4/40\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 0.2013 - acc: 0.9229 - val_loss: 0.1217 - val_acc: 0.9643\n",
      "Epoch 5/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.2293 - acc: 0.9139 - val_loss: 0.0820 - val_acc: 0.9796\n",
      "Epoch 6/40\n",
      "25/25 [==============================] - 1s 29ms/step - loss: 0.1947 - acc: 0.9319 - val_loss: 0.0836 - val_acc: 0.9796\n",
      "Epoch 7/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1696 - acc: 0.9396 - val_loss: 0.0925 - val_acc: 0.9796\n",
      "Epoch 8/40\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 0.1765 - acc: 0.9370 - val_loss: 0.0851 - val_acc: 0.9847\n",
      "Epoch 9/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1825 - acc: 0.9370 - val_loss: 0.0906 - val_acc: 0.9694\n",
      "Epoch 10/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1625 - acc: 0.9499 - val_loss: 0.0972 - val_acc: 0.9745\n",
      "Epoch 11/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1425 - acc: 0.9550 - val_loss: 0.1044 - val_acc: 0.9694\n",
      "Epoch 12/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.1762 - acc: 0.9370 - val_loss: 0.0871 - val_acc: 0.9847\n",
      "Epoch 13/40\n",
      "25/25 [==============================] - 1s 28ms/step - loss: 0.1416 - acc: 0.9512 - val_loss: 0.0864 - val_acc: 0.9745\n",
      "Epoch 14/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1862 - acc: 0.9499 - val_loss: 0.0808 - val_acc: 0.9745\n",
      "Epoch 15/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.1177 - acc: 0.9563 - val_loss: 0.0950 - val_acc: 0.9643\n",
      "Epoch 16/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0937 - acc: 0.9679 - val_loss: 0.0967 - val_acc: 0.9745\n",
      "Epoch 17/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0902 - acc: 0.9692 - val_loss: 0.0837 - val_acc: 0.9694\n",
      "Epoch 18/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1249 - acc: 0.9614 - val_loss: 0.1385 - val_acc: 0.9592\n",
      "Epoch 19/40\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 0.1083 - acc: 0.9589 - val_loss: 0.0683 - val_acc: 0.9796\n",
      "Epoch 20/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0837 - acc: 0.9666 - val_loss: 0.0940 - val_acc: 0.9643\n",
      "Epoch 21/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1323 - acc: 0.9576 - val_loss: 0.0712 - val_acc: 0.9796\n",
      "Epoch 22/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1065 - acc: 0.9614 - val_loss: 0.0735 - val_acc: 0.9745\n",
      "Epoch 23/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0952 - acc: 0.9666 - val_loss: 0.0913 - val_acc: 0.9745\n",
      "Epoch 24/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0888 - acc: 0.9756 - val_loss: 0.0979 - val_acc: 0.9643\n",
      "Epoch 25/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0722 - acc: 0.9653 - val_loss: 0.0957 - val_acc: 0.9745\n",
      "Epoch 26/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0819 - acc: 0.9692 - val_loss: 0.0618 - val_acc: 0.9847\n",
      "Epoch 27/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0958 - acc: 0.9614 - val_loss: 0.1079 - val_acc: 0.9643\n",
      "Epoch 28/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0902 - acc: 0.9666 - val_loss: 0.1024 - val_acc: 0.9592\n",
      "Epoch 29/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1204 - acc: 0.9640 - val_loss: 0.1010 - val_acc: 0.9745\n",
      "Epoch 30/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0863 - acc: 0.9666 - val_loss: 0.0783 - val_acc: 0.9796\n",
      "Epoch 31/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0694 - acc: 0.9717 - val_loss: 0.0833 - val_acc: 0.9745\n",
      "Epoch 32/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.1010 - acc: 0.9589 - val_loss: 0.1402 - val_acc: 0.9592\n",
      "Epoch 33/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0794 - acc: 0.9704 - val_loss: 0.0663 - val_acc: 0.9745\n",
      "Epoch 34/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0734 - acc: 0.9756 - val_loss: 0.0680 - val_acc: 0.9745\n",
      "Epoch 35/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0694 - acc: 0.9730 - val_loss: 0.0686 - val_acc: 0.9745\n",
      "Epoch 36/40\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0675 - acc: 0.9794 - val_loss: 0.0648 - val_acc: 0.9847\n",
      "Epoch 37/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0729 - acc: 0.9666 - val_loss: 0.0674 - val_acc: 0.9898\n",
      "Epoch 38/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0930 - acc: 0.9756 - val_loss: 0.0913 - val_acc: 0.9745\n",
      "Epoch 39/40\n",
      "25/25 [==============================] - 1s 27ms/step - loss: 0.0910 - acc: 0.9730 - val_loss: 0.1062 - val_acc: 0.9694\n",
      "Epoch 40/40\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.0450 - acc: 0.9756 - val_loss: 0.0834 - val_acc: 0.9847\n"
     ]
    }
   ],
   "source": [
    "# Final Classifier\n",
    "start = datetime.datetime.now()\n",
    "model = Sequential() \n",
    "model.add(Flatten(input_shape=STACKED_FEATURES_TRAINX.shape[1:])) \n",
    "model.add(Dense(512, activation=keras.layers.LeakyReLU(alpha=0.01))) \n",
    "model.add(Dropout(0.7)) \n",
    "model.add(Dense(512, activation=keras.layers.LeakyReLU(alpha=0.03))) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.01))) \n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "   optimizer='adam',\n",
    "   metrics=['acc'])\n",
    "\n",
    "history = model.fit(STACKED_FEATURES_TRAINX, STACKED_FEATURES_TRAINY, \n",
    "   epochs=40,\n",
    "   validation_data=(STACKED_FEATURES_VALX, STACKED_FEATURES_VALY))\n",
    "#model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21b238aa",
   "metadata": {
    "id": "21b238aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0834 - acc: 0.9847\n",
      "[INFO] accuracy: 98.47%\n",
      "[INFO] Loss: 0.08338256925344467\n",
      "Time:  0:00:26.674291\n"
     ]
    }
   ],
   "source": [
    "# Val set Eualvation\n",
    "(eval_loss, eval_accuracy) = model.evaluate( \n",
    "    STACKED_FEATURES_VALX, STACKED_FEATURES_VALY, batch_size=batch_size,     verbose=1)\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
    "print(\"[INFO] Loss: {}\".format(eval_loss)) \n",
    "end= datetime.datetime.now()\n",
    "elapsed= end-start\n",
    "print ('Time: ', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ac7347a",
   "metadata": {
    "id": "1ac7347a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] accuracy: 98.47%\n",
      "[INFO] Loss: 0.08338256925344467\n"
     ]
    }
   ],
   "source": [
    "# Plots and results\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.title(\"All features Combined\")\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100)) \n",
    "print(\"[INFO] Loss: {}\".format(eval_loss)) "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MainColab.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0753047ff6bc463bbbaaadd1e8843b66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5fb59a281014af48e96e1742bffaa08",
      "max": 6,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a6fbc9664cf243bdbaf663956add756e",
      "value": 3
     }
    },
    "245fbd7f51904e7b8693c3b4fa92f13b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37f7c3d87c154a9fb19942a08df9c4fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e2e4fce17b14b1092b1fb8efe029935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e31b6e5bfc3432588afe98fd7c51421": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df8d7760414a4491ae02a72058a56bb7",
      "placeholder": "",
      "style": "IPY_MODEL_963e4cde82ee4a009f0c33926612cf97",
      "value": " 50%"
     }
    },
    "9288f87ef8a748cdb256907c80e96481": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37f7c3d87c154a9fb19942a08df9c4fe",
      "placeholder": "",
      "style": "IPY_MODEL_5e2e4fce17b14b1092b1fb8efe029935",
      "value": " 3/6 [42:20&lt;44:18, 886.12s/it]"
     }
    },
    "963e4cde82ee4a009f0c33926612cf97": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6fbc9664cf243bdbaf663956add756e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b5fb59a281014af48e96e1742bffaa08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc614f2308e34444b6874503507dd858": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8e31b6e5bfc3432588afe98fd7c51421",
       "IPY_MODEL_0753047ff6bc463bbbaaadd1e8843b66",
       "IPY_MODEL_9288f87ef8a748cdb256907c80e96481"
      ],
      "layout": "IPY_MODEL_245fbd7f51904e7b8693c3b4fa92f13b"
     }
    },
    "df8d7760414a4491ae02a72058a56bb7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
